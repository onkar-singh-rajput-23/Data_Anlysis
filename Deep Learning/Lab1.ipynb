{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5uOxtDe0lHb/gj0d0aXBK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"cpu\"\n",")"],"metadata":{"id":"R1pIeH89XW7f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import Dataloader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","\n"],"metadata":{"id":"kQ5U3U-3T7hK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ude-TuegXa2s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fkTrm8xCZnIX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cLjw58lTGOR"},"outputs":[],"source":["class NN(nn.Module):\n","  def __init__(self):\n","    super(NN, self).__init__()\n","    self.fc1 = nn.liner(input_size , 64)\n","    self.fc2 = nn.liner(64 , 64)\n","    self.output = nn.liner(64 , classes)\n","\n","  def forword(self , x):\n","    x = self.x = x.view(-1, 28 * 28) #view or flattern\n","    x = self.x(32*32 , 64)\n","    x = self.relu(x)\n","    x = self.fc1(x)\n","    x = self.fc2(x)\n","    x = self.output(x)\n","\n","\n","input_size = 16*16\n","classes = 10\n","learninig_rate = 0.001\n","batch = 8\n","epoch= 2\n"]},{"cell_type":"code","source":["\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor()\n",")"],"metadata":{"id":"JAjZQnhKZpim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training = dataloader(trainingdata , batch_size = batch , suffle = True )\n","testig  = dataloader(testingingdata , batch_size = batch , suffle = True )\n"],"metadata":{"id":"OEupeE0GZVtx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RjnbAG3Za4u6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modle = NN(input_size = input_size , num_clasess = clasess).to(device)\n","#  optimizaation and loss funtion\n","criterion = nn.crossEntropyLoss()\n","optimizer = optim.Adam(modle.parameater , lr = learning_rate)\n","\n"],"metadata":{"id":"glaGNdXSa5of"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","for epoch in range(epochs):\n","    model.train()\n","    for images, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Validation loop\n","    model.eval()\n","    with torch.no_grad():\n","        all_labels = []\n","        all_predictions = []\n","        for images, labels in test_loader:\n","            outputs = model(images)\n","            _, predictions = torch.max(outputs, 1)\n","            all_labels.extend(labels.numpy())\n","            all_predictions.extend(predictions.numpy())\n","\n","        accuracy = accuracy_score(all_labels, all_predictions)\n","        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Accuracy: {accuracy:.4f}')\n","\n","# Test the trained model\n","model.eval()\n","with torch.no_grad():\n","    all_labels = []\n","    all_predictions = []\n","    for images, labels in test_loader:\n","        outputs = model(images)\n","        _, predictions = torch.max(outputs, 1)\n","        all_labels.extend(labels.numpy())\n","        all_predictions.extend(predictions.numpy())\n","\n","accuracy = accuracy_score(all_labels, all_predictions)\n","print(f'Test Accuracy: {accuracy:.4f}')"],"metadata":{"id":"QFCGffyLpc7d"},"execution_count":null,"outputs":[]}]}